{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Collecting posts from 2 subreddits using Reddit's API, use NLP techniques to train a classifier for which subreddit each post comes from.\n",
    "\n",
    "Project Overview:\n",
    "NLP techniques that will be used are CountVectorizer and Tfid-Ifd. For each technique, different models will be tested. These models are Naive Bayes' models, Multinomial; Gaussian; Bernoulli and other classification models such as KNN and Logistic Regression. KNN and Logistic Regression models will be subjected to a grid search to better optimize the model. For every model used, the confusion matrix and ROC AUC will be used to evaluate each classification model's effectiveness. \n",
    "\n",
    "As the project is not linear; the procedure for one NLP technique, one model and its associated performance is:\n",
    "- Extracting the posts using Reddit API\n",
    "- EDA to identify target columns\n",
    "- NLP transformation\n",
    "- Modelling\n",
    "- Classification model performance\n",
    "\n",
    "## *Note: Please Run Notebook from middle*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Posts Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_1 = \"https://www.reddit.com/r/Warframe/hot.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to specify user-agent because default using python, it has its own user-agent. Therefore, with many users \n",
    "#connecting to the web at the same time, it will return response code of 429.\n",
    "headers = {'User-agent' : 'Evan 0.1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_1 = requests.get(url_1, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_1.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_json = res_1.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'kind']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(war_json.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['after', 'before', 'children', 'dist', 'modhash']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(war_json['data'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(war_json['data']['children'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t3_asfcn4',\n",
       " 't3_chp9zc',\n",
       " 't3_chl4nh',\n",
       " 't3_chrku6',\n",
       " 't3_chr960',\n",
       " 't3_chotwt',\n",
       " 't3_chn98j',\n",
       " 't3_chr7ue',\n",
       " 't3_chqnyj',\n",
       " 't3_cho3jx',\n",
       " 't3_chrssn',\n",
       " 't3_chqah7',\n",
       " 't3_cho5rm',\n",
       " 't3_chl296',\n",
       " 't3_chmm3s',\n",
       " 't3_chhaxp',\n",
       " 't3_chtask',\n",
       " 't3_chqa2u',\n",
       " 't3_chkwfq',\n",
       " 't3_chunuo',\n",
       " 't3_chsar5',\n",
       " 't3_chuebe',\n",
       " 't3_chhb42',\n",
       " 't3_cht1zt',\n",
       " 't3_chmngh',\n",
       " 't3_chsrix',\n",
       " 't3_chl0av']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_id = [i['data']['name'] for i in war_json['data']['children']]\n",
    "list_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t3_chl0av'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "war_json['data']['after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'after': war_json['data']['after']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(url_1, params=param, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "#extract the posts data\n",
    "posts_war = []\n",
    "after = None\n",
    "for i in range(40):\n",
    "    print(i)\n",
    "    if after == None:\n",
    "        params = {}\n",
    "    else: \n",
    "        params = {'after': after}\n",
    "    url_1= \"https://www.reddit.com/r/Warframe/hot.json\"\n",
    "    res_1 = requests.get(url_1, params=params, headers=headers)\n",
    "    if res_1.status_code == 200:\n",
    "        war_json = res_1.json()\n",
    "        posts_war.extend(war_json['data']['children'])\n",
    "        after = war_json['data']['after']\n",
    "    else:\n",
    "        print(res_1.status_code)\n",
    "        break\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts_war)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to check for repetition\n",
    "len(set(i['data']['name'] for i in posts_war))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are 102 posts because the first 2 of the posts are pinned and are not considered in the 25post/page limit\n",
    "posts_war = posts_war[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "981"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts_war)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeat the above steps for the other sub reddit page: apexlegends\n",
    "url_2 = \"https://www.reddit.com/r/apexlegends/hot.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-agent' : 'Bleep blorp bot 0.1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_2 = requests.get(url_2, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_2.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "apex_json = res_2.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'kind']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(apex_json.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['after', 'before', 'children', 'dist', 'modhash']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(apex_json['data'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(apex_json['data']['children'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t3_chgblz',\n",
       " 't3_chhsse',\n",
       " 't3_cho5h3',\n",
       " 't3_chlndk',\n",
       " 't3_chrqq6',\n",
       " 't3_chojfp',\n",
       " 't3_chqjc3',\n",
       " 't3_chlya1',\n",
       " 't3_chhsje',\n",
       " 't3_cho85f',\n",
       " 't3_chp0kn',\n",
       " 't3_chnzo3',\n",
       " 't3_chox8p',\n",
       " 't3_chsfjf',\n",
       " 't3_chqqq5',\n",
       " 't3_chdaal',\n",
       " 't3_chp4cs',\n",
       " 't3_cho6yy',\n",
       " 't3_chsncv',\n",
       " 't3_chrl7c',\n",
       " 't3_chomyj',\n",
       " 't3_chq98u',\n",
       " 't3_chs336',\n",
       " 't3_chr3ea',\n",
       " 't3_chslxg',\n",
       " 't3_chirab',\n",
       " 't3_chtlkq']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_id_apex = [i['data']['name'] for i in apex_json['data']['children']]\n",
    "list_id_apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t3_chtlkq'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apex_json['data']['after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'after': apex_json['data']['after']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(url_1, params=param, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"&amp;#x200B;\\n\\nhttps://i.redd.it/qeb183dqacc31.png\\n\\n# Apex Legends Community Reward Challenge\\n\\nWelcome to the first Apex Legends art related challenge!\\n\\nWe at r/ApexLegends are about to finalize a relatively new Reddit feature - [Community Rewards](https://www.reddit.com/r/redesign/comments/c3psbg/community_awards_everything_you_need_to_know/).\\n\\nYou can read more about community rewards in the link.\\n\\n&amp;#x200B;\\n\\n**Whenever you see a popular post, it's very likely that the post has received Reddit Rewards. Silver, Gold &amp; Platinum. Community Rewards are more or less the same, but instead of having silver, gold &amp; platinum, we can make custom rewards with custom icons up to a total of 7 rewards. This is where you talented people come in. In order for us to properly be able to populate the different rewards, we want to put your skills to the test to create the artwork!**\\n\\n&amp;#x200B;\\n\\n&amp;#x200B;\\n\\n|Placing|Price|\\n|:-|:-|\\n|1st up to 7th|Your icon will be added to a personal unique flair + Credit in winner post.|\\n\\n&amp;#x200B;\\n\\n# How to submit:\\n\\n&amp;#x200B;\\n\\nWe originally tried doing this as a contest thread but quickly realized it wasn't working as planned. NEW PLAN!\\n\\n* Submit your artwork using this Google form: [https://forms.gle/TnbfdqZiKUbGyBUz8](https://forms.gle/TnbfdqZiKUbGyBUz8)\\n* **All artwork already posted on this thread has been submitted!**\\n* Submissions will be closed on Sunday (July 28 11pm PST): [Countdown timer](https://www.timeanddate.com/countdown/generic?iso=20190728T23&amp;p0=239&amp;msg=r%2FApexLegends+Community+Reward+Challenge&amp;font=serif&amp;csz=1)\\n\\nAfter submissions are closed, we'll make another post with individual comments of each submissions. \\n\\nThat thread will be in CONTEST MODE and locked so only voting on those submissions can happen. \\n\\nAfter voting is closed, we'll announce all of the winners and set up the Community Awards section!\\n\\n# Rules:\\n\\n&amp;#x200B;\\n\\n* All contributions must to be related to Apex Legends.\\n* Image width and height should be equal, and **at least** 512px.\\n* Background **must** be transparent and image must be in a .png format.\\n* Mods will collect all submissions and create a voting thread in contest mode with individual comments of each submission.\\n* Winners are then determined by most up-voted comments.\\n\\n&amp;#x200B;\\n\\n**You may not:**\\n\\n* Use any Inappropriate, NSFW, Gore or Sexual content.\\n* Use someone else's content.\\n\\n# Competition Ends: 28th of July 2019 11pm PST  - [Countdown Timer](https://www.timeanddate.com/countdown/generic?iso=20190728T23&amp;p0=239&amp;msg=r%2FApexLegends+Community+Reward+Challenge&amp;font=serif&amp;csz=1)\\n\\n&amp;#x200B;\\n\\nThis is an example of the community rewards and how It would look.\\n\\n&amp;#x200B;\\n\\nhttps://i.redd.it/6mxq11xv9hc31.png\\n\\n[\\\\( Thanks to u\\\\/FrozenFroh \\\\)](https://i.redd.it/w79c05jkbgc31.png)\\n\\n[Less is often more.](https://i.redd.it/pskdg2lcdgc31.png)\\n\\n[Too many details more often than not disappears.](https://i.redd.it/4r3gfzkcdgc31.png)\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of text in first post for apex\n",
    "apex_json['data']['children'][0]['data']['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[r/ApexLegends] Community Reward Challenge'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of title in first post for apex\n",
    "apex_json['data']['children'][0]['data']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1564013703.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of timestamp in first post for apex\n",
    "apex_json['data']['children'][0]['data']['created_utc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of number of comments\n",
    "apex_json['data']['children'][0]['data']['num_comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apexlegends'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of subreddit\n",
    "apex_json['data']['children'][0]['data']['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "#extract the posts data\n",
    "posts_apex = []\n",
    "after = None\n",
    "for i in range(40):\n",
    "    print(i)\n",
    "    if after == None:\n",
    "        params = {}\n",
    "    else: \n",
    "        params = {'after': after}\n",
    "    url_2= \"https://www.reddit.com/r/apexlegends/hot.json\"\n",
    "    res_2 = requests.get(url_2, params=params, headers=headers)\n",
    "    if res_2.status_code == 200:\n",
    "        apex_json = res_2.json()\n",
    "        posts_apex.extend(apex_json['data']['children'])\n",
    "        after = apex_json['data']['after']\n",
    "    else:\n",
    "        print(res_2.status_code)\n",
    "        break\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "982"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts_apex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "830"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to check for repetition\n",
    "len(set(i['data']['name'] for i in posts_apex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_apex = posts_apex[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts_apex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract title, subreddit, length of time it has been up and number of comments, text in posts.\n",
    "data_apex = {\n",
    "    'title': [i['data']['title'] for i in posts_apex], \n",
    "    'subreddit': [i['data']['subreddit'] for i in posts_apex], \n",
    "    'time': [i['data']['created_utc'] for i in posts_apex], \n",
    "    'comments': [i['data']['num_comments'] for i in posts_apex],\n",
    "    'text': [i['data']['selftext'] for i in posts_apex]\n",
    "}\n",
    "\n",
    "df_apex = pd.DataFrame(data_apex, columns = data_apex.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>time</th>\n",
       "      <th>comments</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No one gets my gold armor!</td>\n",
       "      <td>apexlegends</td>\n",
       "      <td>1.564064e+09</td>\n",
       "      <td>152</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I need more of this on my insta feed</td>\n",
       "      <td>apexlegends</td>\n",
       "      <td>1.564049e+09</td>\n",
       "      <td>147</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tried to do Fight Club but they wanted the win</td>\n",
       "      <td>apexlegends</td>\n",
       "      <td>1.564080e+09</td>\n",
       "      <td>34</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mirage here to save the day</td>\n",
       "      <td>apexlegends</td>\n",
       "      <td>1.564066e+09</td>\n",
       "      <td>41</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not a high kill count or damage count. But man...</td>\n",
       "      <td>apexlegends</td>\n",
       "      <td>1.564075e+09</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title    subreddit  \\\n",
       "0                         No one gets my gold armor!  apexlegends   \n",
       "1               I need more of this on my insta feed  apexlegends   \n",
       "2     Tried to do Fight Club but they wanted the win  apexlegends   \n",
       "3                        Mirage here to save the day  apexlegends   \n",
       "4  Not a high kill count or damage count. But man...  apexlegends   \n",
       "\n",
       "           time  comments text  \n",
       "0  1.564064e+09       152       \n",
       "1  1.564049e+09       147       \n",
       "2  1.564080e+09        34       \n",
       "3  1.564066e+09        41       \n",
       "4  1.564075e+09        12       "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_apex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_war = {\n",
    "    'title': [i['data']['title'] for i in posts_war], \n",
    "    'subreddit': [i['data']['subreddit'] for i in posts_war], \n",
    "    'time': [i['data']['created_utc'] for i in posts_war], \n",
    "    'comments': [i['data']['num_comments'] for i in posts_war],\n",
    "    'text': [i['data']['selftext'] for i in posts_war]\n",
    "}\n",
    "\n",
    "df_war = pd.DataFrame(data_war, columns = data_war.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>time</th>\n",
       "      <th>comments</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warframe Sbubby 2: Electric Boogaloo</td>\n",
       "      <td>Warframe</td>\n",
       "      <td>1.564045e+09</td>\n",
       "      <td>247</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Umbra(cat) vs Shawzin</td>\n",
       "      <td>Warframe</td>\n",
       "      <td>1.564079e+09</td>\n",
       "      <td>20</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember... Even if your dreams are gone it's ...</td>\n",
       "      <td>Warframe</td>\n",
       "      <td>1.564078e+09</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So I did a thing (better with sound)</td>\n",
       "      <td>Warframe</td>\n",
       "      <td>1.564067e+09</td>\n",
       "      <td>56</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hey Listen !</td>\n",
       "      <td>Warframe</td>\n",
       "      <td>1.564059e+09</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title subreddit          time  \\\n",
       "0               Warframe Sbubby 2: Electric Boogaloo  Warframe  1.564045e+09   \n",
       "1                              Umbra(cat) vs Shawzin  Warframe  1.564079e+09   \n",
       "2  Remember... Even if your dreams are gone it's ...  Warframe  1.564078e+09   \n",
       "3               So I did a thing (better with sound)  Warframe  1.564067e+09   \n",
       "4                                       Hey Listen !  Warframe  1.564059e+09   \n",
       "\n",
       "   comments text  \n",
       "0       247       \n",
       "1        20       \n",
       "2         8       \n",
       "3        56       \n",
       "4         9       "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_war.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_apex, df_war])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>time</th>\n",
       "      <th>comments</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No one gets my gold armor!</td>\n",
       "      <td>apexlegends</td>\n",
       "      <td>1.564064e+09</td>\n",
       "      <td>152</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I need more of this on my insta feed</td>\n",
       "      <td>apexlegends</td>\n",
       "      <td>1.564049e+09</td>\n",
       "      <td>147</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tried to do Fight Club but they wanted the win</td>\n",
       "      <td>apexlegends</td>\n",
       "      <td>1.564080e+09</td>\n",
       "      <td>34</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mirage here to save the day</td>\n",
       "      <td>apexlegends</td>\n",
       "      <td>1.564066e+09</td>\n",
       "      <td>41</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not a high kill count or damage count. But man...</td>\n",
       "      <td>apexlegends</td>\n",
       "      <td>1.564075e+09</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title    subreddit  \\\n",
       "0                         No one gets my gold armor!  apexlegends   \n",
       "1               I need more of this on my insta feed  apexlegends   \n",
       "2     Tried to do Fight Club but they wanted the win  apexlegends   \n",
       "3                        Mirage here to save the day  apexlegends   \n",
       "4  Not a high kill count or damage count. But man...  apexlegends   \n",
       "\n",
       "           time  comments text  \n",
       "0  1.564064e+09       152       \n",
       "1  1.564049e+09       147       \n",
       "2  1.564080e+09        34       \n",
       "3  1.564066e+09        41       \n",
       "4  1.564075e+09        12       "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['apexlegends'] = pd.get_dummies(df['subreddit']).drop(columns=['Warframe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='subreddit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>time</th>\n",
       "      <th>comments</th>\n",
       "      <th>text</th>\n",
       "      <th>apexlegends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No one gets my gold armor!</td>\n",
       "      <td>1.564064e+09</td>\n",
       "      <td>152</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I need more of this on my insta feed</td>\n",
       "      <td>1.564049e+09</td>\n",
       "      <td>147</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tried to do Fight Club but they wanted the win</td>\n",
       "      <td>1.564080e+09</td>\n",
       "      <td>34</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mirage here to save the day</td>\n",
       "      <td>1.564066e+09</td>\n",
       "      <td>41</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not a high kill count or damage count. But man...</td>\n",
       "      <td>1.564075e+09</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title          time  comments  \\\n",
       "0                         No one gets my gold armor!  1.564064e+09       152   \n",
       "1               I need more of this on my insta feed  1.564049e+09       147   \n",
       "2     Tried to do Fight Club but they wanted the win  1.564080e+09        34   \n",
       "3                        Mirage here to save the day  1.564066e+09        41   \n",
       "4  Not a high kill count or damage count. But man...  1.564075e+09        12   \n",
       "\n",
       "  text  apexlegends  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./datasets/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Run Notebook from here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find X and y\n",
    "X = df['title'] + df['text']\n",
    "y = df['apexlegends']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) NLP Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will be done using CountVectorizer together with the models used:\n",
    "1) Multinomial NB\n",
    "2) Bernoulli NB\n",
    "3) Gaussian NB\n",
    "4) Logistic Regression + Grid Search\n",
    "5) KNN + Grid Search\n",
    "\n",
    "Each classification method will be evaluated based on the following:\n",
    "1) Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvec = CountVectorizer(stop_words='english', token_pattern=r'(?u)\\b[a-zA-Z]{2,}\\b')\n",
    "X_train_cvec = cvec.fit_transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "just        502\n",
       "game        440\n",
       "like        420\n",
       "warframe    263\n",
       "amp         252\n",
       "know        229\n",
       "time        224\n",
       "https       211\n",
       "don         202\n",
       "apex        186\n",
       "ve          184\n",
       "new         172\n",
       "play        172\n",
       "got         158\n",
       "think       152\n",
       "good        147\n",
       "people      146\n",
       "playing     145\n",
       "damage      144\n",
       "use         143\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check out the most common words\n",
    "X_df = pd.DataFrame(cvec.transform(X_train).todense(),\n",
    "                       columns=cvec.get_feature_names())\n",
    "word_counts = pd.DataFrame(X_df).sum(axis=0)\n",
    "word_counts.sort_values(ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score on train data: 0.991156462585034\n",
      "model score on test data: 0.8533604887983707\n",
      "Number of features: 7572\n"
     ]
    }
   ],
   "source": [
    " #can try other kinds of vectorizer like tf-idf\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = make_pipeline(CountVectorizer(stop_words='english',\n",
    "                                      token_pattern=r'(?u)\\b[a-zA-Z]{2,}\\b'),\n",
    "                      LogisticRegression(solver='lbfgs'),\n",
    "                      )\n",
    "\n",
    "model_count = model.fit(X_train, y_train)\n",
    "y_pred = model_count.predict(X_test)\n",
    "print('model score on train data: {}'.format(model_count.score(X_train, y_train)))\n",
    "print('model score on test data: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Number of features:\", len(model.steps[0][1].get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch was attempted and excluded because there was no change.\n",
    "# Import the confusion matrix function.\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[195,  51],\n",
       "       [ 21, 224]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 195\n",
      "False Positives: 51\n",
      "False Negatives: 21\n",
      "True Positives: 224\n"
     ]
    }
   ],
   "source": [
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score on train data: 0.7959183673469388\n",
      "model score on test data: 0.6415478615071283\n",
      "Number of features: 7572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = make_pipeline(CountVectorizer(stop_words='english',\n",
    "                                      token_pattern=r'(?u)\\b[a-zA-Z]{2,}\\b'),\n",
    "                      KNeighborsClassifier(),\n",
    "                      )\n",
    "\n",
    "model_count = model.fit(X_train, y_train)\n",
    "y_pred = model_count.predict(X_test)\n",
    "print('model score on train data: {}'.format(model_count.score(X_train, y_train)))\n",
    "print('model score on test data: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Number of features:\", len(model.steps[0][1].get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 9 folds for each of 10 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:   36.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=9, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_neighbors': range(1, 10, 2), 'metric': ['euclidean', 'manhattan']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "knn_params = {\n",
    "    'n_neighbors': range(1,10, 2),\n",
    "    'metric' : ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "knn_gridsearch = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    knn_params,\n",
    "    cv=9,\n",
    "    verbose=1,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "knn_gridsearch.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6510204081632653"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'euclidean', 'n_neighbors': 1}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to fit do a cvec first before fitting into knn, as shown above it can be done using pipeline alone\n",
    "#however we want to use the best parameter model from our girdsearch and git manually hence the need.\n",
    "knn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
    "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
    "           weights='uniform')\n",
    "model = knn.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7659863945578231"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6028513238289206"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test_cvec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[187,  59],\n",
       "       [136, 109]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 187\n",
      "False Positives: 59\n",
      "False Negatives: 136\n",
      "True Positives: 109\n"
     ]
    }
   ],
   "source": [
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our model! for Multinomial\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score on train data: 0.9591836734693877\n",
      "model score on test data: 0.8818737270875764\n",
      "Number of features: 7572\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(CountVectorizer(stop_words='english',\n",
    "                                      token_pattern=r'(?u)\\b[a-zA-Z]{2,}\\b'),\n",
    "                      MultinomialNB(),\n",
    "                      )\n",
    "\n",
    "model_count = model.fit(X_train, y_train)\n",
    "y_pred = model_count.predict(X_test)\n",
    "#note that even though X_train is not CountVectorizer fit_transformed, using model_count takes into account\n",
    "#pipeline characteristics, allowing raw X_train to be used here.\n",
    "print('model score on train data: {}'.format(model_count.score(X_train, y_train)))\n",
    "print('model score on test data: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Number of features:\", len(model.steps[0][1].get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[215,  31],\n",
       "       [ 27, 218]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a confusion matrix.\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 215\n",
      "False Positives: 31\n",
      "False Negatives: 27\n",
      "True Positives: 218\n"
     ]
    }
   ],
   "source": [
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use of BernoulliNB model to classify (elaborate a bit about how it works), expected to be better or worse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score on train data: 0.8006802721088435\n",
      "model score on test data: 0.7515274949083504\n",
      "Number of features: 7572\n"
     ]
    }
   ],
   "source": [
    "#Import Bernoulli and edit pipeline from above\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = make_pipeline(CountVectorizer(stop_words='english',\n",
    "                                      token_pattern=r'(?u)\\b[a-zA-Z]{2,}\\b'),\n",
    "                      BernoulliNB(),\n",
    "                      )\n",
    "\n",
    "\n",
    "model_count = model.fit(X_train, y_train)\n",
    "y_pred = model_count.predict(X_test)\n",
    "print('model score on train data: {}'.format(model_count.score(X_train, y_train)))\n",
    "print('model score on test data: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Number of features:\", len(model.steps[0][1].get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[128, 118],\n",
       "       [  4, 241]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a confusion matrix.\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 128\n",
      "False Positives: 118\n",
      "False Negatives: 4\n",
      "True Positives: 241\n"
     ]
    }
   ],
   "source": [
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in the ROC AUC as another metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use of GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to reinstantiate the CountVectorizer outside the pipeline in order to obtain an array type for it to be able to fit under a Gaussian Naive Bayes' model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score on train data: 0.9714285714285714\n",
      "model score on test data: 0.8472505091649695\n",
      "Number of features: 7572\n"
     ]
    }
   ],
   "source": [
    "#cvec already defined above\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "X_train_cvec = X_train_cvec.toarray()\n",
    "model_gnb = gnb.fit(X_train_cvec, y_train)\n",
    "X_test_cvec = X_test_cvec.toarray()\n",
    "predictions_gnb = model_gnb.predict(X_test_cvec)\n",
    "print('model score on train data: {}'.format(model_gnb.score(X_train_cvec, y_train)))\n",
    "print('model score on test data: {}'.format(accuracy_score(y_test, predictions_gnb)))\n",
    "print(\"Number of features:\", len(model.steps[0][1].get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[199,  47],\n",
       "       [ 28, 217]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a confusion matrix.\n",
    "cm = confusion_matrix(y_test, predictions_gnb)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_gnb).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 199\n",
      "False Positives: 47\n",
      "False Negatives: 28\n",
      "True Positives: 217\n"
     ]
    }
   ],
   "source": [
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the above steps using Tfid-ifd together with the following models:\n",
    "1) Multinomial\n",
    "2) Bernoulli\n",
    "3) Gaussian\n",
    "\n",
    "Then evaluate similarly for each model with the following classification metrics:\n",
    "1) Confusion matrix\n",
    "2) ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tvec = TfidfVectorizer(stop_words='english', \n",
    "                       sublinear_tf=True,\n",
    "                       max_df=0.7, \n",
    "                       token_pattern=r'(?u)\\b[a-zA-Z]{2,}\\b')\n",
    "X_train_tvec = tvec.fit_transform(X_train)\n",
    "X_test_tvec = tvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score on train data: 0.9850340136054422\n",
      "model score on test data: 0.8655804480651731\n",
      "Number of features: 7572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#import libraries required to use TfidVectorizer\n",
    "model = make_pipeline(TfidfVectorizer(stop_words='english',\n",
    "                        sublinear_tf=True,\n",
    "                        max_df=0.5,\n",
    "                        token_pattern=r'(?u)\\b[a-zA-Z]{2,}\\b'),\n",
    "                      LogisticRegression(),\n",
    "                      )\n",
    "\n",
    "model_tf = model.fit(X_train, y_train)\n",
    "y_pred = model_tf.predict(X_test)\n",
    "print('model score on train data: {}'.format(model_tf.score(X_train, y_train)))\n",
    "print('model score on test data: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Number of features:\", len(model.steps[0][1].get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidfvectorizer': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "         stop_words='english', strip_accents=None, sublinear_tf=True,\n",
       "         token_pattern='(?u)\\\\b[a-zA-Z]{2,}\\\\b', tokenizer=None,\n",
       "         use_idf=True, vocabulary=None),\n",
       " 'logisticregression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False)}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tf.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = pd.DataFrame(model_tf.named_steps.logisticregression.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log.columns = model_tf.named_steps.tfidfvectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaaand</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abc</th>\n",
       "      <th>abilities</th>\n",
       "      <th>abilitiesi</th>\n",
       "      <th>ability</th>\n",
       "      <th>abilityvalkyr</th>\n",
       "      <th>able</th>\n",
       "      <th>abnormally</th>\n",
       "      <th>...</th>\n",
       "      <th>zipline</th>\n",
       "      <th>ziplines</th>\n",
       "      <th>zipped</th>\n",
       "      <th>zipping</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoned</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zopney</th>\n",
       "      <th>zotac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.140789</td>\n",
       "      <td>-0.144448</td>\n",
       "      <td>-0.101362</td>\n",
       "      <td>0.041176</td>\n",
       "      <td>-0.846892</td>\n",
       "      <td>-0.062824</td>\n",
       "      <td>-0.506748</td>\n",
       "      <td>-0.149584</td>\n",
       "      <td>0.061572</td>\n",
       "      <td>0.144559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.28742</td>\n",
       "      <td>0.10457</td>\n",
       "      <td>0.04879</td>\n",
       "      <td>-0.010316</td>\n",
       "      <td>0.074014</td>\n",
       "      <td>0.082609</td>\n",
       "      <td>0.028599</td>\n",
       "      <td>-0.07277</td>\n",
       "      <td>-0.013251</td>\n",
       "      <td>0.042855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 7572 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aaaand  abandoned  abandoning       abc  abilities  abilitiesi   ability  \\\n",
       "0 -0.140789  -0.144448   -0.101362  0.041176  -0.846892   -0.062824 -0.506748   \n",
       "\n",
       "   abilityvalkyr      able  abnormally  ...  zipline  ziplines   zipped  \\\n",
       "0      -0.149584  0.061572    0.144559  ...  0.28742   0.10457  0.04879   \n",
       "\n",
       "    zipping      zone     zoned     zones     zoom    zopney     zotac  \n",
       "0 -0.010316  0.074014  0.082609  0.028599 -0.07277 -0.013251  0.042855  \n",
       "\n",
       "[1 rows x 7572 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = df_log.reset_index() #Make your index into a column\n",
    "df_log = pd.melt(df_log, id_vars = ['index']) #Reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = df_log.drop(columns='index').sort_values(by = 'value') #Remove duplicates, sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7304</th>\n",
       "      <td>warframe</td>\n",
       "      <td>-3.591021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4967</th>\n",
       "      <td>prime</td>\n",
       "      <td>-2.600727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>build</td>\n",
       "      <td>-1.705613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4113</th>\n",
       "      <td>mission</td>\n",
       "      <td>-1.608339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4474</th>\n",
       "      <td>operator</td>\n",
       "      <td>-1.608161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>frame</td>\n",
       "      <td>-1.515252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7507</th>\n",
       "      <td>wukong</td>\n",
       "      <td>-1.366606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>bug</td>\n",
       "      <td>-1.303548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>captura</td>\n",
       "      <td>-1.290037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6685</th>\n",
       "      <td>tenno</td>\n",
       "      <td>-1.277216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4136</th>\n",
       "      <td>mod</td>\n",
       "      <td>-1.267861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>mods</td>\n",
       "      <td>-1.231704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>melee</td>\n",
       "      <td>-1.181448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>fortuna</td>\n",
       "      <td>-1.164226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4116</th>\n",
       "      <td>missions</td>\n",
       "      <td>-1.145510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7312</th>\n",
       "      <td>warframes</td>\n",
       "      <td>-1.098799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018</th>\n",
       "      <td>help</td>\n",
       "      <td>-1.082858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>nightwave</td>\n",
       "      <td>-1.039895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5606</th>\n",
       "      <td>riven</td>\n",
       "      <td>-1.039508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7355</th>\n",
       "      <td>weapons</td>\n",
       "      <td>-1.018000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       variable     value\n",
       "7304   warframe -3.591021\n",
       "4967      prime -2.600727\n",
       "827       build -1.705613\n",
       "4113    mission -1.608339\n",
       "4474   operator -1.608161\n",
       "2584      frame -1.515252\n",
       "7507     wukong -1.366606\n",
       "819         bug -1.303548\n",
       "921     captura -1.290037\n",
       "6685      tenno -1.277216\n",
       "4136        mod -1.267861\n",
       "4152       mods -1.231704\n",
       "4012      melee -1.181448\n",
       "2564    fortuna -1.164226\n",
       "4116   missions -1.145510\n",
       "7312  warframes -1.098799\n",
       "3018       help -1.082858\n",
       "4320  nightwave -1.039895\n",
       "5606      riven -1.039508\n",
       "7355    weapons -1.018000"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 20 key words that are relevant for Warframe\n",
    "df_log.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6657</th>\n",
       "      <td>teammate</td>\n",
       "      <td>1.115199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>bangalore</td>\n",
       "      <td>1.133305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2778</th>\n",
       "      <td>gold</td>\n",
       "      <td>1.139909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3685</th>\n",
       "      <td>legends</td>\n",
       "      <td>1.169517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>clutch</td>\n",
       "      <td>1.206615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3543</th>\n",
       "      <td>kills</td>\n",
       "      <td>1.251683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6292</th>\n",
       "      <td>squad</td>\n",
       "      <td>1.253062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4102</th>\n",
       "      <td>mirage</td>\n",
       "      <td>1.269949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7340</th>\n",
       "      <td>wattson</td>\n",
       "      <td>1.285051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7488</th>\n",
       "      <td>wraith</td>\n",
       "      <td>1.293023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>caustic</td>\n",
       "      <td>1.348523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>lifeline</td>\n",
       "      <td>1.402634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>challenges</td>\n",
       "      <td>1.474484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6658</th>\n",
       "      <td>teammates</td>\n",
       "      <td>1.507763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7417</th>\n",
       "      <td>win</td>\n",
       "      <td>1.511720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3963</th>\n",
       "      <td>match</td>\n",
       "      <td>1.639638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641</th>\n",
       "      <td>pathfinder</td>\n",
       "      <td>1.913341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>game</td>\n",
       "      <td>2.079900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5210</th>\n",
       "      <td>ranked</td>\n",
       "      <td>2.557669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>apex</td>\n",
       "      <td>3.566720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        variable     value\n",
       "6657    teammate  1.115199\n",
       "543    bangalore  1.133305\n",
       "2778        gold  1.139909\n",
       "3685     legends  1.169517\n",
       "1163      clutch  1.206615\n",
       "3543       kills  1.251683\n",
       "6292       squad  1.253062\n",
       "4102      mirage  1.269949\n",
       "7340     wattson  1.285051\n",
       "7488      wraith  1.293023\n",
       "970      caustic  1.348523\n",
       "3730    lifeline  1.402634\n",
       "1008  challenges  1.474484\n",
       "6658   teammates  1.507763\n",
       "7417         win  1.511720\n",
       "3963       match  1.639638\n",
       "4641  pathfinder  1.913341\n",
       "2670        game  2.079900\n",
       "5210      ranked  2.557669\n",
       "290         apex  3.566720"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 20 key words that are relevant for Apex Legends\n",
    "df_log.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[215,  31],\n",
       "       [ 35, 210]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 215\n",
      "False Positives: 31\n",
      "False Negatives: 35\n",
      "True Positives: 210\n"
     ]
    }
   ],
   "source": [
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score on train data: 0.7482993197278912\n",
      "model score on test data: 0.594704684317719\n",
      "Number of features: 7572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "model = make_pipeline(TfidfVectorizer(stop_words='english',\n",
    "                        sublinear_tf=True,\n",
    "                        max_df=0.5,\n",
    "                        token_pattern=r'(?u)\\b[a-zA-Z]{2,}\\b'),\n",
    "                      BaggingClassifier(base_estimator=knn, max_samples=0.5, max_features=0.5)\n",
    "                      )\n",
    "\n",
    "model_tf = model.fit(X_train, y_train)\n",
    "y_pred = model_tf.predict(X_test)\n",
    "print('model score on train data: {}'.format(model_tf.score(X_train, y_train)))\n",
    "print('model score on test data: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Number of features:\", len(model.steps[0][1].get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 9 folds for each of 10 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "knn_params = {\n",
    "    'n_neighbors': range(15,25,2),\n",
    "    'metric' : ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "knn_gridsearch = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    knn_params,\n",
    "    cv=9,\n",
    "    verbose=1,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "knn_gridsearch.fit(X_train_tvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
    "           metric_params=None, n_jobs=None, n_neighbors=19, p=2,\n",
    "           weights='uniform')\n",
    "model = knn.fit(X_train_tvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_train_tvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test_tvec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_tvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(TfidfVectorizer(stop_words='english',\n",
    "                                      sublinear_tf=True,\n",
    "                                      max_df=0.5,\n",
    "                                      token_pattern=r'(?u)\\b[a-zA-Z]{2,}\\b'),\n",
    "                      MultinomialNB(),\n",
    "                      )\n",
    "model_tf = model.fit(X_train, y_train)\n",
    "y_pred = model_tf.predict(X_test)\n",
    "print('model score on train data: {}'.format(model_tf.score(X_train, y_train)))\n",
    "print('model score on test data: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Number of features:\", len(model.steps[0][1].get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi = pd.DataFrame(model_tf.named_steps.multinomialnb.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi.columns = model_tf.named_steps.tfidfvectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi = df_multi.reset_index() #Make your index into a column\n",
    "df_multi = pd.melt(df_multi, id_vars = ['index']) #Reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi = df_multi.drop(columns='index').sort_values(by = 'value') #Remove duplicates, sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 20 key words that are relevant for Warframe\n",
    "df_multi.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 20 key words that are relevant for Apex Legends\n",
    "df_multi.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(TfidfVectorizer(stop_words='english',\n",
    "                                      sublinear_tf=True,\n",
    "                                      max_df=0.7,\n",
    "                                      token_pattern=r'(?u)\\b[a-zA-Z]{2,}\\b'),\n",
    "                      BernoulliNB(),\n",
    "                      )\n",
    "model_tf = model.fit(X_train, y_train)\n",
    "y_pred = model_tf.predict(X_test)\n",
    "print('model score on train data: {}'.format(model_tf.score(X_train, y_train)))\n",
    "print('model score on test data: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Number of features:\", len(model.steps[0][1].get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tvec = X_train_tvec.toarray()\n",
    "model_gnb = gnb.fit(X_train_tvec, y_train)\n",
    "X_test_tvec = X_test_tvec.toarray()\n",
    "predictions_gnb = model_gnb.predict(X_test_tvec)\n",
    "print('model score on train data: {}'.format(model_gnb.score(X_train_tvec, y_train)))\n",
    "print('model score on test data: {}'.format(accuracy_score(y_test, predictions_gnb)))\n",
    "print(\"Number of features:\", len(model.steps[0][1].get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predictions_gnb)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_gnb).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "For this example, there is no difference between a false positive and false negative. A false positive is a post that is predicted to be on Apex Legends and is in fact a WarFrame post. In scenarios where positive outcomes are more serious like detecting cancer, pregnancy or fraud, a false positive is preferred over a false negative. One way to think of this is a false negative is a positive occurence that managed to 'slip' under the radar. Whereas a false positive is negative scenario(usually good) detected as a positive outcome (usually bad and the ones we want to detect). This is a relatively straightforward classification case.\n",
    "\n",
    "A practical use case can be filtering news/forum posts into specific industry news and go further by performing sentiment analysis. This can be useful for market analysis and in today's context, predict a probability of a recession. Comparing traditional ways of doing surveys to collect data, this is a much more efficient way to collect and analyse information. Regardless of where information is collected, one drawback is the quality of information.\n",
    "\n",
    "## Summary between models\n",
    "\n",
    "The ideal model to be used in this case is Multinomial Naive Bayes' model as the columns of X are integer counts. Hence this model is likely to give the highest score. A fairly close result of false negatives and positives is yielded.\n",
    "\n",
    "Bernoulli functions best when the columns of X are dummy variables/one-hot encoded. It is not very applicable here as we can see from the lower model score.\n",
    "\n",
    "Gaussian functions best when the columns of X are Normally distributed. In this case, it is not very applicable as well. One note is it also gives a fairly close result of false negatives and positives unlike the Bernoulli function where false positives >> false negatives.\n",
    "\n",
    "A logistic Regression\n",
    "Grid search was not very useful and returned a best penalty of 1.0. However, the model score is high.\n",
    "\n",
    "KNearestNeighbor (KNN) on its own, the model scored very poorly on the train data and even worse on the test data. There is no change when using grid search to improve the parameters of KNN when using CountVectorizer. However, grid search vastly improved the score of KNN model when using Tfidf-Vectorizer.\n",
    "\n",
    "## Comparison between the 2 vectorizer\n",
    "Modelling wise, the train score tended to be slightly lower for TfidfVectorizer than CountVectorizer. But the test score is improved for TfidfVectorizer as compared to the CountVectorizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
